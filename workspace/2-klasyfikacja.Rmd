---
title: "Podstawowe metody klasyfikacji"
date: "Semestr letni 2021/22"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
library(ISLR)
library(class)
library(dplyr)
library(MASS)
```

## Dane

Używamy zbioru danych Life Expectancy (WHO) dostępnego na Kaggle

https://www.kaggle.com/datasets/kumarajarshi/life-expectancy-who

Wczytujemy dataset z pobranego pliku CSV.

```{r countriesDataSet}
countries <- read.csv("LifeExpectancyData.csv", header = TRUE, na.strings = "?")
```

Dataset zawiera brakujące wartości. W tym projekcie skupiamy sie na prostej klasyfikacji dlatego wykorzystamy prostą metodę usupełniania brakujących wartości średnią z danej kolumny.

Przewidywac będziemy wartości z kolumny `Status` więc od razu wprowadzamy odpowiednie kodowanie.

```{r}
numeric_cols <- sapply(countries, is.numeric)

replace_na_with_mean <- function(x) {
  if(is.numeric(x)) {
    x[is.na(x)] <- mean(x, na.rm = TRUE)
  }
  return(x)
}
countries = countries %>% mutate(target = ifelse(Status == "Developing", 0, 1))
countries_imputed <- as.data.frame(lapply(countries[, numeric_cols], replace_na_with_mean))
countries_processed <- cbind(countries_imputed, countries[, !numeric_cols, drop = FALSE])
head(countries_processed)
attach(countries_processed)
```


Obliczenie korelacji zmiennych numerycznych

```{r cor}
cor(countries_processed[, numeric_cols <- sapply(countries_processed, is.numeric)])
```


```{r plotVolume}
plot(Life.expectancy, Income.composition.of.resources)
```

```{r plotVolume}
plot(Life.expectancy, Adult.Mortality)
```

## Regresja logistyczna

Chcemy dopasować model regresji logistycznej żeby przewidzieć wartość
`Status` na podstawie zmiennych `GDP` + `BMI` + `Schooling` + `under.five.deaths`

```{r logistic}
dir_logistic <- list()
dir_logistic$fit <- glm(target ~ GDP + BMI + Schooling + under.five.deaths, 
                   family = binomial, data = countries_processed)
summary(dir_logistic$fit)
```


Przykład wykorzystania funkcji predict

```{r logisticPredictProbs}
dir_logistic$probs <- predict(dir_logistic$fit, type = "response")
head(dir_logistic$probs)
```


Ostatecznie przewidywane przypisanie do klas uzyskujemy stosując
bayesowską regułę decyzyjną (*maximum a posteriori*).

```{r logisticClass}
dir_logistic$predicted <- ifelse(dir_logistic$probs > 0.5, 1, 0)
```

Macierz pomyłek

```{r logisticConfusionMatrix}
dir_logistic$cm <- table(dir_logistic$predicted, target)
dir_logistic$cm
```

Liczymy proporcję błędów

```{r logisticErrorRate}
mean(dir_logistic$predicted != countries_processed$target)
```

Niestety powyższa proporcja błędów jest *treningową proporcją błędów*.
Do estymacji *testowej proporcji błędów* zastosujemy podział dostępnych
danych na:

-   zbiór uczący --- dane od 2000 do 2012 roku;

-   zbiór testowy --- dane z 2012 - 2015 roku.

```{r trainAndTestSets}
train <- countries_processed$Year < 2012
countries_processed_test <- countries_processed[!train,]
target_test <- countries_processed$target[!train]
```

Regresję wykonujemy na podstawie zbioru uczącego

```{r logisticTrain}
dir_log_t <- list()
dir_log_t$fit <- glm(target ~  GDP + BMI + Schooling + under.five.deaths, 
                   family = binomial, data = countries_processed, subset = train)
summary(dir_log_t$fit)
```

a otrzymany model wykorzystujemy do predykcji dla danych ze zbioru
testowego

```{r logisticPredictionTrain}
dir_log_t$probs <- predict(dir_log_t$fit, countries_processed_test, type = "response")
dir_log_t$predicted <- ifelse(dir_log_t$probs > 0.5, 1, 0)
table(dir_log_t$predicted, target_test)
```

Wyniki w przypadku tego datasetu i podzbioru kolumn są zadowalające ale nie idealne

[**Jaka jest zatem proporcja błędów dla takiego zbioru testowego?**]

Próbujemy uzyskać bardziej efektywny model eliminując najmniej istotne
predyktory. Zostawiamy `GDP` i `Schooling`

```{r logisticSmall}
dir_log_best2 <- list()
dir_log_best2$fit <- glm(target ~ GDP + Schooling, family = binomial, 
                    data = countries_processed, subset = train)
summary(dir_log_best2$fit)
dir_log_best2$probs <- predict(dir_log_best2$fit, countries_processed_test, type = "response")
dir_log_best2$predicted <- ifelse(dir_log_best2$probs > 0.5, 1, 0)
table(dir_log_best2$predicted, target_test)
```


```{r naivePred}
mean(target_test != 0)
```

W przypadku tego datasetu usunięcie najmniej istotnych czynników pogorszyło wynik.

## LDA i QDA

Funkcje `lda()` i `qda()` są zaimplementowane w pakiecie `MASS`.

### LDA

W sytuacji jak poprzednio stosujemy LDA do klasyfikacji wyznaczonej
przez `target` względem `GDP` i `Schooling`.

```{r lda}
dir_lda <- list()
dir_lda$fit <- lda(target ~ BMI + Schooling, data = countries_processed, subset = train)
dir_lda$fit
```

Predykcję wykonuje funkcja `predict.lda()`. Zwraca ona listę, której
komponentami są: wektor przewidywanych klas `class`, wektor
prawdopodobieństw a posteriori `posterior` i wektor wartości liniowego
dyskryminatora `x`.

```{r ldaPredict}
dir_lda$predicted <- predict(dir_lda$fit, countries_processed_test)
table(dir_lda$predicted$class, target_test)
```
Uzyskaliśmy znacznie większą liczbę fałszywych negatwynych wyników i ogółem słabszy wynik


### QDA

Ten sam problem z kwadratowym dyskryminatorem

```{r qda}
dir_qda <- list()
dir_qda$fit <- qda(target ~ BMI + Schooling, data = countries_processed, subset = train)
dir_qda$fit
```

I predykcja

```{r qdaPredict}
dir_qda$predicted <- predict(dir_qda$fit, countries_processed_test)
table(dir_qda$predicted$class, target_test)
```

Uzyskalny wynik jest porównywalny z tym uzyskanym w regresji logistycznej

## kNN

W tym przypadku nie ma jawnego etapu dopasowania. Funkcja `knn()` z
pakietu `class` od razu wykonuje predykcję. Np. ze zbiorem uczącym i
testowym jak poprzednio i z $k = 1$ mamy

```{r knn}
train_set <- countries_processed[train, c("GDP", "Schooling")]
test_set <- countries_processed[!train, c("GDP", "Schooling")]
target_train <- countries_processed$target[train]
dir_knn_1 <- knn(train_set, test_set, target_train, k = 3)
table(dir_knn_1, target_test)
```


```{r knnError}
mean(dir_knn_1 != target_test)
```

Otrzymane wyniki są słabsze niż te otrzymane dla wcześniejszych metod